{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import collections\n",
    "import pickle\n",
    "#import cPickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import codecs\n",
    "from Bio import Medline\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec, Word2Vec, CoherenceModel\n",
    "from gensim.summarization import summarize\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import GapStatistics\n",
    "import time\n",
    "\n",
    "import bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations and Variable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuration: Data file name (it should be placed in the same ditrectory as the notebook file)\n",
    "DATA_FILE = DATA_FILE = '/data/pubmedtext.txt'\n",
    "#test variables\n",
    "# test_pmid = '27179337'\n",
    "test_pmid = '28324318'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constant variables\n",
    "CLEANED_ABSTRACT_COL = 'cleaned_abstract'\n",
    "SUMMARY_ABSTRACT_COL = 'summary_abstract'\n",
    "CLEANED_MINIMAL_ABSTRACT_COL = 'cleaned_minimal_abstract'\n",
    "TOKENIZED_CLEAN_ABS_COL = 'tokenized_c_abstract'\n",
    "TOKENIZED_RAW_ABS_COL = 'tokenized_r_abstract'\n",
    "TOKEN_COUNT_RAW_ABS_COL = 'token_count_r_abstract'\n",
    "TOKEN_COUNT_CLEAN_ABS_COL = 'token_count_c_abstract'\n",
    "TOKEN_COUNT_Unq_CLEAN_ABS_COL = 'token_count_unq_c_abstract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Input File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2author = dict()\n",
    "doc_id_dict = dict()\n",
    "topics=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dictionary of medline terms: https://www.nlm.nih.gov/bsd/mms/medlineelements.html\n",
    "#Note that this differs from above by removing grants and affiliations in an effort to minimize exceptions\n",
    "def read_medline_data_raw(filename):\n",
    "    recs = Medline.parse(open(filename, 'r'))\n",
    "    text = pd.DataFrame(columns = [\"pmid\", \"articletitle\", \"journaltitle\", \"abstract\"])\n",
    "    count = 0\n",
    "    for rec in recs:\n",
    "        try:\n",
    "            pmid = rec['PMID']\n",
    "            atitle = rec[\"TI\"]\n",
    "            jtitle = rec[\"JT\"]\n",
    "            topics.append(jtitle)\n",
    "            pubdate = rec[\"DP\"]\n",
    "            abstr = rec[\"AB\"]\n",
    "            a_name=rec[\"AU\"]\n",
    "            doc2author[count]=a_name\n",
    "            doc_id_dict[count]=count\n",
    "            count=count+1\n",
    "            text = text.append(pd.DataFrame([[pmid,atitle, jtitle,pubdate, abstr]],\n",
    "                columns=[\"pmid\", \"articletitle\", \"journaltitle\", \"pubdate\", \"abstract\"]),ignore_index=True, verify_integrity=True)            \n",
    "        except:\n",
    "            pass\n",
    "    text.set_index(text.pmid)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell started at: Fri May 18 09:22:16 2018\n",
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 110 ms\n",
      "Cell completed at: Fri May 18 09:22:16 2018\n"
     ]
    }
   ],
   "source": [
    "# get the Data file path\n",
    "\n",
    "print(\"Cell started at: \" + time.strftime(\"%c\"))\n",
    "try:\n",
    "    approot = os.path.dirname(os.path.realpath('__file__'))\n",
    "except NameError:  # if it is the main script, not a module\n",
    "    import sys\n",
    "    approot = os.path.dirname(os.path.abspath(sys.argv[0]))\n",
    "DATA_PATH = approot + DATA_FILE\n",
    "\n",
    "# Read in MEDLINE formatted text\n",
    "%time papers = read_medline_data_raw(DATA_PATH)\n",
    "papers.to_pickle('data/papers_pain_EngFilter_6_5_2017_raw_oct17update')\n",
    "papers.to_csv('data/papers_pain_EngFilter_6_5_2017_raw_oct17update.csv')\n",
    "print(\"Cell completed at: \" + time.strftime(\"%c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The international journal of neuropsychopharmacology',\n",
       " 'Expert opinion on pharmacotherapy',\n",
       " 'Health psychology : official journal of the Division of Health Psychology, American Psychological Association',\n",
       " 'Foot & ankle international',\n",
       " 'Expert review of clinical pharmacology',\n",
       " 'Haematologica',\n",
       " 'Head & neck',\n",
       " 'European journal of radiology',\n",
       " 'Experimental brain research',\n",
       " 'Human & experimental toxicology']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics=list(set(topics))\n",
    "topics2=topics[1:11]\n",
    "topics2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "papers = pd.read_pickle('data/papers_pain_EngFilter_6_5_2017_raw_oct17update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61 entries, 0 to 60\n",
      "Data columns (total 5 columns):\n",
      "abstract        61 non-null object\n",
      "articletitle    61 non-null object\n",
      "journaltitle    61 non-null object\n",
      "pmid            61 non-null object\n",
      "pubdate         61 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pubdatevalues = papers.pubdate.unique()\n",
    "#pubdatevalues.tofile(\"pubdatevalues.csv\", sep=',') Examine range of pubdates manually in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "papers['pubdate_dtformat'] = pd.to_datetime(papers.pubdate, format='%Y', exact=False)\n",
    "papers['pubyear'] = pd.DatetimeIndex(papers['pubdate_dtformat']).year\n",
    "papers=papers.drop('pubdate_dtformat', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articletitle</th>\n",
       "      <th>journaltitle</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>pubyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Non-steroidal anti-inflammatory drugs (NSAIDs)...</td>\n",
       "      <td>Anti-inflammatory and antinociceptive activiti...</td>\n",
       "      <td>International immunopharmacology</td>\n",
       "      <td>21855654</td>\n",
       "      <td>2011 Nov</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>We investigated the changes in characteristics...</td>\n",
       "      <td>Expression of inflammatory and apoptosis facto...</td>\n",
       "      <td>International immunopharmacology</td>\n",
       "      <td>21821152</td>\n",
       "      <td>2011 Nov</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>INTRODUCTION: Flupirtine, a nonopioid analgesi...</td>\n",
       "      <td>Efficacy and tolerability of flupirtine in sub...</td>\n",
       "      <td>International journal of clinical pharmacology...</td>\n",
       "      <td>22011688</td>\n",
       "      <td>2011 Nov</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Post-herpetic neuralgia means pain which occur...</td>\n",
       "      <td>Modified Jaipur block for the treatment of pos...</td>\n",
       "      <td>International journal of dermatology</td>\n",
       "      <td>22004501</td>\n",
       "      <td>2011 Nov</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Antipsychotic drugs are the clinical standard ...</td>\n",
       "      <td>Dynamic regulation of dopamine and serotonin r...</td>\n",
       "      <td>The international journal of neuropsychopharma...</td>\n",
       "      <td>21281560</td>\n",
       "      <td>2011 Nov</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BACKGROUND: Sex, race, and age disparities in ...</td>\n",
       "      <td>Patient demographic characteristics and facial...</td>\n",
       "      <td>International journal of nursing studies</td>\n",
       "      <td>21596378</td>\n",
       "      <td>2011 Nov</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>BACKGROUND: Even though the use of a 25 gauge ...</td>\n",
       "      <td>Comparison of post-dural puncture headache and...</td>\n",
       "      <td>International journal of nursing studies</td>\n",
       "      <td>21561619</td>\n",
       "      <td>2011 Nov</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>PURPOSE: We analyzed variables associated with...</td>\n",
       "      <td>Predictors of long-term toxicity using three-d...</td>\n",
       "      <td>International journal of radiation oncology, b...</td>\n",
       "      <td>20933342</td>\n",
       "      <td>2011 Nov 01</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PURPOSE: To correlate computed tomography (CT)...</td>\n",
       "      <td>Correlation of computed tomography imaging fea...</td>\n",
       "      <td>International journal of radiation oncology, b...</td>\n",
       "      <td>20889265</td>\n",
       "      <td>2011 Nov 01</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Rheumatoid arthritis (RA) is one of the inflam...</td>\n",
       "      <td>The antinociceptive efficacy of HWTX-I epidura...</td>\n",
       "      <td>International journal of sports medicine</td>\n",
       "      <td>22052031</td>\n",
       "      <td>2011 Nov</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             abstract  \\\n",
       "51  Non-steroidal anti-inflammatory drugs (NSAIDs)...   \n",
       "52  We investigated the changes in characteristics...   \n",
       "53  INTRODUCTION: Flupirtine, a nonopioid analgesi...   \n",
       "54  Post-herpetic neuralgia means pain which occur...   \n",
       "55  Antipsychotic drugs are the clinical standard ...   \n",
       "56  BACKGROUND: Sex, race, and age disparities in ...   \n",
       "57  BACKGROUND: Even though the use of a 25 gauge ...   \n",
       "58  PURPOSE: We analyzed variables associated with...   \n",
       "59  PURPOSE: To correlate computed tomography (CT)...   \n",
       "60  Rheumatoid arthritis (RA) is one of the inflam...   \n",
       "\n",
       "                                         articletitle  \\\n",
       "51  Anti-inflammatory and antinociceptive activiti...   \n",
       "52  Expression of inflammatory and apoptosis facto...   \n",
       "53  Efficacy and tolerability of flupirtine in sub...   \n",
       "54  Modified Jaipur block for the treatment of pos...   \n",
       "55  Dynamic regulation of dopamine and serotonin r...   \n",
       "56  Patient demographic characteristics and facial...   \n",
       "57  Comparison of post-dural puncture headache and...   \n",
       "58  Predictors of long-term toxicity using three-d...   \n",
       "59  Correlation of computed tomography imaging fea...   \n",
       "60  The antinociceptive efficacy of HWTX-I epidura...   \n",
       "\n",
       "                                         journaltitle      pmid      pubdate  \\\n",
       "51                   International immunopharmacology  21855654     2011 Nov   \n",
       "52                   International immunopharmacology  21821152     2011 Nov   \n",
       "53  International journal of clinical pharmacology...  22011688     2011 Nov   \n",
       "54               International journal of dermatology  22004501     2011 Nov   \n",
       "55  The international journal of neuropsychopharma...  21281560     2011 Nov   \n",
       "56           International journal of nursing studies  21596378     2011 Nov   \n",
       "57           International journal of nursing studies  21561619     2011 Nov   \n",
       "58  International journal of radiation oncology, b...  20933342  2011 Nov 01   \n",
       "59  International journal of radiation oncology, b...  20889265  2011 Nov 01   \n",
       "60           International journal of sports medicine  22052031     2011 Nov   \n",
       "\n",
       "    pubyear  \n",
       "51     2011  \n",
       "52     2011  \n",
       "53     2011  \n",
       "54     2011  \n",
       "55     2011  \n",
       "56     2011  \n",
       "57     2011  \n",
       "58     2011  \n",
       "59     2011  \n",
       "60     2011  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.journaltitle.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "papers.to_pickle('data/papers_pain_EngFilter_6_5_2017_raw_oct17update_Mar18year')\n",
    "papers = pd.read_pickle('data/papers_pain_EngFilter_6_5_2017_raw_oct17update_Mar18year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text Cleanup & Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Remove \"all-caps:\" section headers, punctuation marks, numbers, and option for words in all capital letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will use regular expressions to remove all:\n",
    "#  (1) words/phrases in all caps followed by :, (if filter_all_caps = True, eveything all-caps will be removed)     \n",
    "#  (2) numbers\n",
    "#  (3) one letter words (such as n or p or other mathematical symbols)\n",
    "#  (4) punctuation marks\n",
    "# return value is the list of all filtered words (except for numbers), and the clean abstracts\n",
    "\n",
    "# A utility function for flattening the lists\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, collections.Iterable) and not isinstance(el, str):\n",
    "            for sub in flatten(el):\n",
    "                yield sub\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "# Filter text as described above            \n",
    "def filterText(abstracts, filter_all_caps = False):    \n",
    "    #define the regex pattern\n",
    "    regex = re.compile('[%s]' % re.escape(re.sub('-', '', string.punctuation)))\n",
    "    if filter_all_caps:\n",
    "        pattern = regex.pattern + r\"|\\b[A-Z]{2,}|[0-9]+|\\b\\w\\b|\\d-\\d|\\W-\\W|\\s-\\s\" \n",
    "    else:\n",
    "        pattern = regex.pattern + r\"|(((\\s|^)[A-Z]{2,}(,)*)*)(\\s|^)(\\b[A-Z]{2,}):|[0-9]+|\\b\\w\\b|\\d-\\d|\\W-\\W|\\s-\\s\" \n",
    "    \n",
    "    #The list of all filtered words (except for numbers)\n",
    "    # convert to a falttened set for faster results\n",
    "    all_filtered_series = abstracts.apply(lambda d: re.findall(pattern, d))\n",
    "    all_filtered = set(flatten(all_filtered_series.tolist()))\n",
    "    non_digit_filtered = [y for y in all_filtered if not y.isdigit()]\n",
    "    \n",
    "    #remove whatever needs to be filtered\n",
    "    abstracts = abstracts.apply(lambda d: re.sub(pattern, '', d))\n",
    "    abstracts = abstracts.apply(lambda d: re.sub('s-s', '', d))\n",
    "    \n",
    "    return abstracts, non_digit_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will replace all the stop words, it also gets rid of the whitespaces\n",
    "def removeWord(text, stop_list):\n",
    "    new_text = []\n",
    "    \n",
    "    #first convert to a list\n",
    "    text_list = str.split(text)\n",
    "    \n",
    "    #check for stop words\n",
    "    for x in text_list:\n",
    "        if x not in stop_list:\n",
    "            new_text.append(x)\n",
    "    \n",
    "    #convert back to string\n",
    "    new_text_str = ' '.join(new_text)\n",
    "    \n",
    "    return new_text_str\n",
    "\n",
    "# This function will remove stop words using NLTK stop word list\n",
    "# It will return processed abstracts and stop word list\n",
    "def removeStopWords(abstracts):         \n",
    "    # use NLTK's default stop word list\n",
    "    stop_set = set(stopwords.words('english'))\n",
    "    \n",
    "    # find all stop words and remove them\n",
    "    abstracts = abstracts.apply(lambda d: removeWord(d, stop_set))\n",
    "    \n",
    "    return abstracts, stop_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert to lower case, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This fuction will convert everything to lower-case\n",
    "def changeToLowerCase(abstracts):  \n",
    "    abstracts = abstracts.apply(lambda d: d.lower())\n",
    "    return abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will tokenize all sentences\n",
    "def tokenizeAbstracts(abstracts):  \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = abstracts.apply(lambda d: tokenizer.tokenize(d))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Combine Preprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessAbstracts(abstracts):    \n",
    "    # Remove all-caps words, numbers, 1-letter words, punctuation marks \n",
    "    abstracts, filtered = filterText(abstracts, filter_all_caps= False)\n",
    "    \n",
    "    # conevrt to lower-case\n",
    "    abstracts = changeToLowerCase(abstracts)\n",
    "    \n",
    "    # Remove stop words\n",
    "    abstracts, stop_list = removeStopWords(abstracts)\n",
    "    filtered = filtered + list(stop_list)\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = tokenizeAbstracts(abstracts)\n",
    "    \n",
    "    return abstracts, tokens, filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be helpful for word2vec models that need minimal preprocessing\n",
    "def minimallyPreprocessAbstracts(abstracts):\n",
    "    #define the regex pattern\n",
    "    regex = re.compile('[%s]' % re.escape(re.sub('-', '', string.punctuation)))\n",
    "    pattern = regex.pattern + r\"|[0-9.]+\" \n",
    "    \n",
    "    #remove whatever needs to be filtered\n",
    "    abstracts = abstracts.apply(lambda d: re.sub(pattern, '#NUM', d))\n",
    "    abstracts = abstracts.apply(lambda d: re.sub('s-s', '', d))\n",
    "    return abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 ms, sys: 0 ns, total: 3.88 ms\n",
      "Wall time: 3.89 ms\n"
     ]
    }
   ],
   "source": [
    "# preprocess the abstracts\n",
    "papers[CLEANED_ABSTRACT_COL], papers[TOKENIZED_CLEAN_ABS_COL], filtered = preprocessAbstracts(papers.abstract)\n",
    "papers[CLEANED_MINIMAL_ABSTRACT_COL] = minimallyPreprocessAbstracts(papers.abstract)\n",
    "%time papers[TOKENIZED_RAW_ABS_COL] = tokenizeAbstracts(papers.abstract)\n",
    "# pre-compute the token counts\n",
    "papers[TOKEN_COUNT_CLEAN_ABS_COL] =papers[TOKENIZED_CLEAN_ABS_COL].map(lambda text: len(text))\n",
    "papers[TOKEN_COUNT_RAW_ABS_COL] =papers[TOKENIZED_RAW_ABS_COL].map(lambda text: len(text))\n",
    "papers[TOKEN_COUNT_Unq_CLEAN_ABS_COL] =papers[TOKENIZED_CLEAN_ABS_COL].map(lambda text: len(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' CASE', ' ', 'DESIGN', ' RESULTS AND', 'LIMITATIONS', 'OPINION', 'OBJECTIVES', ' DESIGN AND', 'CONCLUSIONS', ' AND', 'UNLABELLED', 'PURPOSE', ' EXPERT', ' PATIENTS AND', 'PATIENTS', 'METHOD', 'BACKGROUND AND', 'BACKGROUND', 'INTRODUCTION', 'AIMS', 'COVERED', 'AIM', 'OBJECTIVE', ' METHODS AND', ' MATERIALS AND', 'PARTICIPANTS', 'MATERIALS', 'REPORT', 'RESULTS', ' AREAS', 'SETTINGS', 'CONCLUSION', 'METHODS', 'against', 'shouldn', 'down', 'haven', 'each', 'o', 'be', 'can', 'such', 'isn', 've', 'couldn', 'who', 'when', 'what', \"didn't\", \"hasn't\", 'me', 'm', 'nor', \"don't\", 'why', \"should've\", 'ain', 'if', 'further', 'by', 'the', 'won', \"it's\", 'whom', 's', 'll', 'it', 'did', 'mightn', 'he', 'more', 'wasn', 'any', 'wouldn', 'as', \"aren't\", \"you've\", 'over', 'that', 'were', 'themselves', 'or', 'is', 'weren', 'being', \"shan't\", 'then', \"she's\", 'himself', 'hasn', 'don', 'y', 'before', 'mustn', 'up', 'until', 'its', 'same', 'she', 'most', 'out', 'her', 't', 'does', \"wouldn't\", \"you'd\", \"shouldn't\", 'aren', \"doesn't\", 'has', 'after', 'own', 'so', 'in', \"couldn't\", \"hadn't\", 'am', 'this', 'between', 'not', 'your', 'at', 'both', \"you'll\", 'his', 'where', 'you', 'those', 'theirs', 'having', 'will', 'than', 'for', 'about', 'from', 'him', 'itself', \"haven't\", 'but', 'with', \"wasn't\", 'doesn', 'on', 'how', 'and', 'once', 'doing', 'no', 're', 'ma', 'some', 'only', 'myself', 'been', 'shan', 'ourselves', 'through', 'all', 'yours', 'their', 'just', 'yourself', 'to', 'too', 'above', 'below', 'have', 'other', \"needn't\", \"weren't\", 'during', 'again', 'under', \"mightn't\", 'i', 'off', 'very', 'an', 'had', 'which', 'was', 'didn', 'because', 'hadn', 'here', 'do', \"you're\", 'are', 'these', 'our', 'while', 'should', \"that'll\", 'they', 'herself', 'now', 'my', 'needn', 'yourselves', 'them', 'd', \"mustn't\", 'hers', \"won't\", 'into', 'ours', 'few', 'there', 'we', 'a', 'of', \"isn't\"]\n"
     ]
    }
   ],
   "source": [
    "#Show list of filtered terms\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.55 ms, sys: 167 µs, total: 5.71 ms\n",
      "Wall time: 5.74 ms\n"
     ]
    }
   ],
   "source": [
    "papers.to_pickle('data/papapers_pain_EngFilter_6_5_2017_raw_preprocessed_oct17update_Mar18years')\n",
    "%time papers = pd.read_pickle('data/papapers_pain_EngFilter_6_5_2017_raw_preprocessed_oct17update_Mar18years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Abstract: \n",
      " Series([], Name: abstract, dtype: object)\n",
      "\n",
      "Cleaned Abstract: \n",
      " Series([], Name: cleaned_abstract, dtype: object)\n",
      "\n",
      "Tokenized Abstract: \n",
      " Series([], Name: tokenized_c_abstract, dtype: object)\n",
      "\n",
      "Minimally Processed Abstract: \n",
      " Series([], Name: cleaned_minimal_abstract, dtype: object)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articletitle</th>\n",
       "      <th>journaltitle</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>pubyear</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>tokenized_c_abstract</th>\n",
       "      <th>cleaned_minimal_abstract</th>\n",
       "      <th>tokenized_r_abstract</th>\n",
       "      <th>token_count_c_abstract</th>\n",
       "      <th>token_count_r_abstract</th>\n",
       "      <th>token_count_unq_c_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [abstract, articletitle, journaltitle, pmid, pubdate, pubyear, cleaned_abstract, tokenized_c_abstract, cleaned_minimal_abstract, tokenized_r_abstract, token_count_c_abstract, token_count_r_abstract, token_count_unq_c_abstract]\n",
       "Index: []"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "print('Original Abstract: \\n', papers.abstract[papers.pmid == test_pmid])\n",
    "print('\\nCleaned Abstract: \\n', papers.loc[papers.pmid == test_pmid, CLEANED_ABSTRACT_COL])\n",
    "print('\\nTokenized Abstract: \\n', papers.loc[papers.pmid == test_pmid, TOKENIZED_CLEAN_ABS_COL])\n",
    "print('\\nMinimally Processed Abstract: \\n', papers.loc[papers.pmid == test_pmid, CLEANED_MINIMAL_ABSTRACT_COL])\n",
    "papers[(papers.pmid == test_pmid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using ATM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create Corpus, Dictionary, and Related Text Constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary mapping words to ids\n",
    "abstract_list = papers[TOKENIZED_CLEAN_ABS_COL].values\n",
    "ca_gs_dictionary = corpora.Dictionary(abstract_list)\n",
    "\n",
    "#remove extremes (similar to tf-idf)\n",
    "ca_gs_dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "ca_gs_dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert the dictionary to a bag of words\n",
    "ca_gs_corpus = [ca_gs_dictionary.doc2bow(words) for words in abstract_list]\n",
    "# corpora.mmcorpus.MmCorpus.serialize('data/ca_gensim.mm', corpus)\n",
    "_ = ca_gs_dictionary[0]  # This sort of \"initializes\" dictionary.id2token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.5 ms, sys: 0 ns, total: 62.5 ms\n",
      "Wall time: 46.2 ms\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import AuthorTopicModel\n",
    "%time model = AuthorTopicModel(corpus=ca_gs_corpus, num_topics=10, id2word=ca_gs_dictionary.id2token, \\\n",
    "                doc2author=doc2author, chunksize=2000, passes=1, eval_every=0, \\\n",
    "                iterations=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 s, sys: 113 ms, total: 18.9 s\n",
      "Wall time: 9.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_list = []\n",
    "for i in range(5):\n",
    "    model = AuthorTopicModel(corpus=ca_gs_corpus, num_topics=10, id2word=ca_gs_dictionary.id2token, \\\n",
    "                    doc2author=doc2author, chunksize=2000, passes=100, gamma_threshold=1e-10, \\\n",
    "                    eval_every=0, iterations=1, random_state=i)\n",
    "    top_topics = model.top_topics(ca_gs_corpus)\n",
    "    tc = sum([t[1] for t in top_topics])\n",
    "    model_list.append((model, tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic coherence: -8.402e+01\n"
     ]
    }
   ],
   "source": [
    "model, tc = max(model_list, key=lambda x: x[1])\n",
    "print('Topic coherence: %.3e' %tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model.\n",
    "model.save('/tmp/model.atmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model.\n",
    "model = AuthorTopicModel.load('/tmp/model.atmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('patients', 0.012712839735249984),\n",
       " ('health', 0.011901774296122885),\n",
       " ('naproxen', 0.0081182757969928375),\n",
       " ('care', 0.0073345639440587423),\n",
       " ('conditions', 0.0071971177019728976),\n",
       " ('patient', 0.0071937039119465392),\n",
       " ('physical', 0.0071550196952673605),\n",
       " ('present', 0.006842090166583231),\n",
       " ('disease', 0.0067002584982109618),\n",
       " ('year', 0.0063025249701358149)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_labels=topics2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: The international journal of neuropsychopharmacology\n",
      "Words: patients health naproxen care conditions patient physical present disease year \n",
      "\n",
      "Label: Expert opinion on pharmacotherapy\n",
      "Words: pain induced acute inflammatory anti visual discomfort clinical facet activities \n",
      "\n",
      "Label: Health psychology : official journal of the Division of Health Psychology, American Psychological Association\n",
      "Words: patients ami clinical ct coronary cdb levels patient diagnosis increased \n",
      "\n",
      "Label: Foot & ankle international\n",
      "Words: pain treatment cortex dopamine patients fear headache children pituitary values \n",
      "\n",
      "Label: Expert review of clinical pharmacology\n",
      "Words: pain patients post chronic patient study activated treatment disease age \n",
      "\n",
      "Label: Haematologica\n",
      "Words: pain patients treatment haemophilia surgery quality life underwent review surgical \n",
      "\n",
      "Label: Head & neck\n",
      "Words: patients pain ssc treatment flupirtine efficacy data active skin score \n",
      "\n",
      "Label: European journal of radiology\n",
      "Words: using patients pain long term volume chronic inflammatory responses one \n",
      "\n",
      "Label: Experimental brain research\n",
      "Words: patients gord pain using positive ibs chest bowel syndrome irritable \n",
      "\n",
      "Label: Human & experimental toxicology\n",
      "Words: pain group rs np lbp compared drg related scores significantly \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in model.show_topics(num_topics=10):\n",
    "    print('Label: ' + topic_labels[topic[0]])\n",
    "    words = ''\n",
    "    for word, prob in model.show_topic(topic[0]):\n",
    "        words += word + ' '\n",
    "    print('Words: ' + words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.54436973607307071), (1, 0.39202442195244247)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['Stelzeneder D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def show_author(name):\n",
    "    print('\\n%s' % name)\n",
    "    #print('Docs:', model.author2doc[name])\n",
    "    print('Journals:')\n",
    "    pprint([(topic_labels[topic[0]], topic[1]) for topic in model[name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stelzeneder D\n",
      "Journals:\n",
      "[('The international journal of neuropsychopharmacology', 0.54436973607307071),\n",
      " ('Expert opinion on pharmacotherapy', 0.39202442195244247)]\n"
     ]
    }
   ],
   "source": [
    "show_author('Stelzeneder D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dogan M\n",
      "Journals:\n",
      "[('The international journal of neuropsychopharmacology', 0.83385582859807827),\n",
      " ('Health psychology : official journal of the Division of Health Psychology, '\n",
      "  'American Psychological Association',\n",
      "  0.028496938839331708),\n",
      " ('Expert review of clinical pharmacology', 0.086408456898801583)]\n"
     ]
    }
   ],
   "source": [
    "show_author('Dogan M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quan GM\n",
      "Journals:\n",
      "[('The international journal of neuropsychopharmacology', 0.021895163154751939),\n",
      " ('Haematologica', 0.6110058839438216),\n",
      " ('European journal of radiology', 0.33874664992282055)]\n"
     ]
    }
   ],
   "source": [
    "show_author('Quan GM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uesugi K\n",
      "Journals:\n",
      "[('Health psychology : official journal of the Division of Health Psychology, '\n",
      "  'American Psychological Association',\n",
      "  0.16914440782994661),\n",
      " ('Human & experimental toxicology', 0.81428597386071266)]\n"
     ]
    }
   ],
   "source": [
    "show_author('Uesugi K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import atmodel\n",
    "author2doc = atmodel.construct_author2doc(model.doc2author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.92282602571\n"
     ]
    }
   ],
   "source": [
    "# Compute the per-word bound.\n",
    "# Number of words in corpus.\n",
    "corpus_words = sum(cnt for document in model.corpus for _, cnt in document)\n",
    "\n",
    "# Compute bound and divide by number of words.\n",
    "perwordbound = model.bound(model.corpus, author2doc=model.author2doc, \\\n",
    "                           doc2author=model.doc2author) / corpus_words\n",
    "print(perwordbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.1 ms, sys: 0 ns, total: 27.1 ms\n",
      "Wall time: 27.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time top_topics = model.top_topics(model.corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.72 s, sys: 438 ms, total: 5.16 s\n",
      "Wall time: 5.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "smallest_author = 0  # Ignore authors with documents less than this.\n",
    "authors = [model.author2id[a] for a in model.author2id.keys() if len(model.author2doc[a]) >= smallest_author]\n",
    "_ = tsne.fit_transform(model.state.gamma[authors, :])  # Result stored in tsne.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"36f94b3e-db58-4f3d-959e-a0bf3dd21d8e\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"36f94b3e-db58-4f3d-959e-a0bf3dd21d8e\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"36f94b3e-db58-4f3d-959e-a0bf3dd21d8e\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '36f94b3e-db58-4f3d-959e-a0bf3dd21d8e' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"36f94b3e-db58-4f3d-959e-a0bf3dd21d8e\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"36f94b3e-db58-4f3d-959e-a0bf3dd21d8e\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"36f94b3e-db58-4f3d-959e-a0bf3dd21d8e\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '36f94b3e-db58-4f3d-959e-a0bf3dd21d8e' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"36f94b3e-db58-4f3d-959e-a0bf3dd21d8e\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tell Bokeh to display plots inside the notebook.\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"4fb49d02-8f65-4811-ad44-5e550507a78b\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"a26ad894-4951-499e-85d1-323689dd4bcd\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"b0b1e9b0-d6b5-4601-a4ae-2989f4644a0c\",\"type\":\"BasicTicker\"},{\"attributes\":{\"source\":{\"id\":\"a5903060-6dbc-47d6-ac52-81a5c65e9865\",\"type\":\"ColumnDataSource\"}},\"id\":\"32f5f626-46a9-49c8-9d04-78c41d091439\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null},\"id\":\"000af6c2-0511-4db7-beea-42dbdf72aa9b\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.6},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":null},\"radius\":{\"field\":\"radii\",\"units\":\"data\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"12670a91-dedf-428a-aff1-14c835991579\",\"type\":\"Circle\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"radius\":{\"field\":\"radii\",\"units\":\"data\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"cffc5fe3-fe78-459c-a115-1f94c4afdcc0\",\"type\":\"Circle\"},{\"attributes\":{\"data_source\":{\"id\":\"a5903060-6dbc-47d6-ac52-81a5c65e9865\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"12670a91-dedf-428a-aff1-14c835991579\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"cffc5fe3-fe78-459c-a115-1f94c4afdcc0\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"32f5f626-46a9-49c8-9d04-78c41d091439\",\"type\":\"CDSView\"}},\"id\":\"992c129a-a98b-4dc0-b2f6-f8905d99fec0\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":{\"id\":\"f29f7668-5ab3-4bfa-b535-dfede8966e2f\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"861b0bfc-f0a1-43be-a390-8e821b5ca7ef\",\"type\":\"BasicTicker\"}},\"id\":\"b4d7b0fa-1124-435b-8a9b-a2aabd32ede5\",\"type\":\"Grid\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"3ac5dce4-c5c9-465b-b47b-4ba571a914c7\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"f29f7668-5ab3-4bfa-b535-dfede8966e2f\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b0b1e9b0-d6b5-4601-a4ae-2989f4644a0c\",\"type\":\"BasicTicker\"}},\"id\":\"154ab22f-33ad-4c24-8e9f-b076e9e05fef\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"d62f50fc-e990-48f4-a387-8a8dab9e2719\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"b276157c-69d1-4e7e-ae8b-8be1adacabfe\",\"type\":\"CrosshairTool\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"author\",\"@author_names\"],[\"size\",\"@author_sizes\"]]},\"id\":\"47a49f4d-b9b3-466f-bc9a-9921083e530c\",\"type\":\"HoverTool\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"02fe8423-9fda-46e2-9df7-d5fc4427c433\",\"type\":\"Title\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"47a49f4d-b9b3-466f-bc9a-9921083e530c\",\"type\":\"HoverTool\"},{\"id\":\"b276157c-69d1-4e7e-ae8b-8be1adacabfe\",\"type\":\"CrosshairTool\"},{\"id\":\"5fd49d39-e1dd-4f47-81dd-5c73eae4c53f\",\"type\":\"PanTool\"},{\"id\":\"684ea716-425a-4bbc-bc81-2ed9289041e1\",\"type\":\"WheelZoomTool\"},{\"id\":\"5a4667e8-fc69-49b3-96d6-4f53938d69ee\",\"type\":\"BoxZoomTool\"},{\"id\":\"2ac4f1b9-2fd2-4b1a-879a-5a8822e6dc78\",\"type\":\"ResetTool\"},{\"id\":\"1471aa4f-7171-484d-bce6-2bb092fda359\",\"type\":\"SaveTool\"},{\"id\":\"6b2a5f90-7a05-4a60-bb31-eafb4632c71e\",\"type\":\"LassoSelectTool\"}]},\"id\":\"80b3cd37-60d8-4f9d-aec6-d420f541260f\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"5fd49d39-e1dd-4f47-81dd-5c73eae4c53f\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"684ea716-425a-4bbc-bc81-2ed9289041e1\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"11012747-75ec-4209-a295-a74dd6e2a252\",\"type\":\"LinearScale\"},{\"attributes\":{\"overlay\":{\"id\":\"3ac5dce4-c5c9-465b-b47b-4ba571a914c7\",\"type\":\"BoxAnnotation\"}},\"id\":\"5a4667e8-fc69-49b3-96d6-4f53938d69ee\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"formatter\":{\"id\":\"d62f50fc-e990-48f4-a387-8a8dab9e2719\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"f29f7668-5ab3-4bfa-b535-dfede8966e2f\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b0b1e9b0-d6b5-4601-a4ae-2989f4644a0c\",\"type\":\"BasicTicker\"}},\"id\":\"3cda0c1b-b8f5-45be-9f69-49d2e56f91ba\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"2ac4f1b9-2fd2-4b1a-879a-5a8822e6dc78\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\",\"author_names\",\"author_sizes\",\"radii\"],\"data\":{\"author_names\":[\"Aarts L\",\"Actis Dato GM\",\"Afif-Abdo J\",\"Akins S\",\"Akyazi H\",\"Akyildiz HY\",\"Albano M\",\"Amato D\",\"Andrell P\",\"Anyfantakis G\",\"Araya G\",\"Arendt-Nielsen L\",\"Aurouer N\",\"Ausania F\",\"Baek GH\",\"Baltaci D\",\"Barbuscia M\",\"Bardi GL\",\"Barnes E\",\"Barthelemy JC\",\"Bhusari P\",\"Boermeester MA\",\"Bogyo M\",\"Borjesson M\",\"Bork K\",\"Boutzouvis S\",\"Bouwense SA\",\"Bowers A\",\"Brabant G\",\"Bremner AP\",\"Bruno MJ\",\"Buchfelder M\",\"Bunnett NW\",\"Busch OR\",\"Cagiano R\",\"Cahen DL\",\"Caiazzo P\",\"Cairoli CE\",\"Calbi F\",\"Callander SB\",\"Campos S\",\"Cardile AP\",\"Casabona R\",\"Cattaruzza F\",\"Chambers CT\",\"Chao PL\",\"Chen PY\",\"Chessell IP\",\"Chi Miao L\",\"Chin M\",\"Chow E\",\"Christakis M\",\"Chu MK\",\"Chularojanamontri L\",\"Chung CS\",\"Coarfa C\",\"Colaco NC\",\"Connes P\",\"Coventry LL\",\"Culleton S\",\"Cumming V\",\"Dahan A\",\"Damiao R\",\"Danjoux C\",\"Davies SE\",\"De Clerck LS\",\"De Martino C\",\"Del Ponte S\",\"Del Vecchio G\",\"Di Lascio P\",\"Diallo A\",\"Diaz MA\",\"Dickert J\",\"Dijkgraaf MG\",\"Dimcevski G\",\"Dipalma G\",\"Dogan M\",\"Donovan A\",\"Drewes AM\",\"El-Gabalawy R\",\"Elion J\",\"Evans L\",\"Falidas E\",\"Farquhar-Smith P\",\"Filtz KR\",\"Finkelstein J\",\"Finn J\",\"Firat C\",\"Flocco R\",\"Fockens P\",\"Ford M\",\"Forsennati PG\",\"Friedrich KM\",\"Frokjaer JB\",\"Fu JG\",\"Fujiwara K\",\"Galdino SL\",\"Ganly I\",\"Gibbs P\",\"Gibbs R\",\"Gimson AE\",\"Glina S\",\"Goed S\",\"Goncalves-Silva T\",\"Gong HS\",\"Gouma DJ\",\"Gram M\",\"Graversen C\",\"Grills IS\",\"Grosemans S\",\"Gu Yang T\",\"Guerra AS\",\"Hans G\",\"Harbeck B\",\"Hardy-Dessources MD\",\"Hatcher JP\",\"Hawkins J\",\"Hellman E\",\"Henry SM\",\"Highlander S\",\"Hirsh AT\",\"Hoeck HC\",\"Holden L\",\"Holgers KM\",\"Holle D\",\"Howden CW\",\"Hue O\",\"Hughes JP\",\"Hughes N\",\"Huh JK\",\"Ibeakanma C\",\"Ickmans K\",\"Im HJ\",\"Inchingolo AD\",\"Inchingolo AM\",\"Inchingolo F\",\"Irei M\",\"Jacobs JV\",\"Jin HW\",\"Joa Qin C\",\"Johnson E\",\"Jones E\",\"Kahraman AS\",\"Kahraman B\",\"Kahrilas PJ\",\"Kaida C\",\"Kanteshwari K\",\"Kapur S\",\"Kara IH\",\"Karahan OI\",\"Karatas E\",\"Katsarava Z\",\"Kestin LL\",\"Khan L\",\"Kikuchi S\",\"Kim AJ\",\"Kim LH\",\"Kim M\",\"Kim SH\",\"Kirkwood K\",\"Kizilay A\",\"Klose S\",\"Knight-Madden J\",\"Kogan M\",\"Konno S\",\"Kraus DH\",\"Kuipers EJ\",\"Kulthanan K\",\"Lamont K\",\"Laramee P\",\"Laranjeira LP\",\"Larsson G\",\"Lee JO\",\"Lehnert H\",\"Lentini M\",\"Leserman J\",\"Lin L\",\"Lin LR\",\"Liu JC\",\"Liu LL\",\"Loffredo A\",\"Lu CX\",\"Lynch SV\",\"Lyo V\",\"Mackenzie CS\",\"Maclean L\",\"Maia MB\",\"Malta DJ\",\"Manapajon A\",\"Mandal D\",\"Mannheimer C\",\"Mao Cai W\",\"Marrelli M\",\"Martin CE\",\"Martini C\",\"Maru R\",\"Mathioulakis S\",\"McGrath PJ\",\"McMurtry CM\",\"Meeus M\",\"Messner A\",\"Milosavljevic A\",\"Mishra AK\",\"Mistretta TA\",\"Mitera G\",\"Moorkens G\",\"Mueller-Schwefe GH\",\"Mulder CJ\",\"Muller CP\",\"Mungan S\",\"Naka M\",\"Natesan S\",\"Nebor D\",\"Nedrebo BG\",\"Nguyen J\",\"Nijs J\",\"Nio Y\",\"Noel M\",\"Novoa R\",\"Ntasi A\",\"Nucera D\",\"Obeid I\",\"Obermann M\",\"Oh JH\",\"Oh K\",\"Olesen SS\",\"Olofsen E\",\"Pallister I\",\"Palussiere J\",\"Paparo D\",\"Parisi F\",\"Park H\",\"Pastore M\",\"Peng H\",\"Pereira SP\",\"Petrosino JF\",\"Pflueger V\",\"Pham D\",\"Pieber K\",\"Pitta Ida R\",\"Podo Brunetti S\",\"Pointillart V\",\"Probyn L\",\"Punta G\",\"Puri N\",\"Qin X\",\"Quan GM\",\"Rauws EA\",\"Raza S\",\"Reid H\",\"Reid M\",\"Riehle K\",\"Riley RR\",\"Robinson ME\",\"Rocha-Filho PA\",\"Romana M\",\"Romeo G\",\"Rubenstein J\",\"Sahgal A\",\"Sansone F\",\"Santa Maria CF\",\"Sareen J\",\"Saulnier DM\",\"Scheurecker G\",\"Schwartz SA\",\"Sekiguchi M\",\"Sen S\",\"Senol S\",\"Sethabutra P\",\"Shaitelman SF\",\"Shirahatti R\",\"Shooshtari S\",\"Shulman RJ\",\"Softeland E\",\"Souza-e-Silva HR\",\"Sridhar R\",\"Stelzeneder D\",\"Sturniolo G\",\"Taranto F\",\"Tarullo A\",\"Tatullo M\",\"Terhaag B\",\"Thanavaro JL\",\"Thanavaro KL\",\"Thomas B\",\"Tonante A\",\"Tramutoli PR\",\"Trattnig S\",\"Trotter DR\",\"Tsao M\",\"Tuna IS\",\"Ueberall MA\",\"Uesugi K\",\"Valdez-Morales E\",\"Vanner SJ\",\"Versalovic J\",\"Vicini FA\",\"Villias C\",\"Vital JM\",\"Vlachos K\",\"Vlychou M\",\"Wajsbrot D\",\"Watanabe K\",\"Wechter ME\",\"Weidler EM\",\"Welsch GH\",\"Wen Tao Z\",\"Whitham JA\",\"Wilder-Smith CH\",\"Wilder-Smith OH\",\"Witkop M\",\"Wonderling D\",\"Wood RL\",\"Yabuki S\",\"Yaguchi C\",\"Yan D\",\"Yang TC\",\"Yassen A\",\"Yavarian Y\",\"Yavich L\",\"Ye H\",\"Yee A\",\"Yikilmaz A\",\"Ying R\",\"Yoon H\",\"Zhang L\",\"Zhang ZY\",\"Zingarelli E\",\"Zolnoun DA\",\"de Lima Mdo C\"],\"author_sizes\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,2,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"radii\":[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.1,0.1,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1],\"x\":{\"__ndarray__\":\"6q+jQebK48AOPtrACTpiQQvmjcBFVFTBg1ZFQPt+REFs4j3Bx3lKQeTH0sCmqQ/BNlxYQRYxjMDngppA4NmvwIdKk8AlUtTAvuqmQBWHI8FwlXTA9lpuQdCqBsFr4j3BB3YBwHuZTEEZ0B9BC8oWwePV4kClYQnBHeZWQU/ZpUBAm5PAQRZfQTqK2T9PSoJBE0NTQFnl0cCO6lFAWKpVweDnwUC79KPAlawBwVSrmcAECA9B0cTXwAnKlUFuMXFB7A2PQeSS5b9ykpdAfHS+QOLiA8EaHvK/VR8DwSUW7UDPbeTAPK/3wM5+BsFnIYdAX9sDwbCZoUHkXuXAATjGQEqym8Az2OPAemlFQO1dNsFodVlAzVdTQDMbWEHxwOVACY2fwGjAhEFZWE3Bb8R6QUAe1cCfzlRAkrhfwflYncB1Tw3Bcy5FwVV1SkGUO6jAULpHwVFnyUB9jA7BkPcpwZIJy8DOKFdBInGzQKX/2cDn06bAcoNZwaIERsEPYn1AFl3FwFcFY0G9e5nASBjtQAj/Q0HNEpbATo6jwDOjqsAfpHpAaL2EQT/QH0GxRE/Bt0yMQVQAIMH3y4hBNUS/wCVzA8EkGo5A2hr0wMD2WUH+GhzBMdFKQYA0h0DwnONAFoBSwS6sD8H/crhAjxuMwBZKJEFPyyFBoZrzwJELS0EAyCFBeXSRQDLoCsHv6RHBZmMBwfd3ckFFDXtBTSgjQKpAiUA61YJAH4o3wep7jEGvoRVB8jcNwX6f+cB9BvPATsYhQTz3fECYjnFBwKQxQTvwoMCMGFPBqhAAwdDUKEFCXpZB5JlxQJi7e0Dp1FtB6uKNQaOLR8H1h3pA8dsKwXaSAMEO1sZAjq16QbdM5r+Yu3tAVwVjQaYvfUEOjvK/o3jmvzrOgUHQparA9q+IwCMEjkCGdJBAhK+BwA+/EUFRDY9BCWpFwenUW0HHU0bB+09XQIZlQ8GFCOZAr1wMwWpcpMA3NObA/ziYwEkn2sCiaOu/5mXuQELiPcFwfYxBJk+DQGg//EDYY6JBAwCswD1XSkF4uStBR40kQSr+AcGNpLPApHzuQNiimsAK7NBAbS2/QHwCGsEerAHArQSfwK/PUUHnC7LAT9KJQHAGQ0EMBhnBGvFMwXT01sAF9PnADn1hQVgDKEH4oNrAU8RQQfJBjMBCWlxBxo0nQaN5mUCpjwTBVNkfQU6kpEEim+3Aw5ZXQaVlhcARruXAddYhQYywN0DjrIFBztOEQTF+z0BjjrPA25EFwYuis8DpFb7As5J5QWb4XEHrQbJAqITFwLZC+0BcwOVA7f5eQdRvZEHKiNlAgqojwcabF8ENWtdAVnFMQY6QWMEYJy9BBRP5wNQMgsDwA8ZAiuDKQC4308AGfuXAPvmbwCiJ2ECjiKrAmEFfQZi7e0DC+IrALERSwbkT8L+Br5BB4phvwNFqnsBpRc9AamtPwRwnL0Erq3PABjmqwDXfgcDUPZvACZV5QbeqeUGYtADAYrKqwL18qcCwFWzAumKbwMpqRUA/DLPAR9dJwYp/rUC321TBqqoAwP/tbUAgPhDB2zQRwTTD2EC6hY9B3qdPQStAXEF9c1BBs5+iwIOw4sCzpoVAzicaQXZc0UDR+qXAZQyPQaZPSsFnbmZBwFAgQSV6UkFEC1JBUozzwLOmhUBjzYRAOW+SQWWzRMFRHqJBAM8gQaXRM0FXhZVBRkOwQDmqWcG6fYxBQSK+QPFKwEDDT0DBs/kQwRqRBUFnWo3A\",\"dtype\":\"float32\",\"shape\":[330]},\"y\":{\"__ndarray__\":\"SQqEvosKBMHX4gxBuTQxwWKS28CtrRfBSus0vx0BWUDMdlm/bH7cwP+CAUEj1DdBvEcWwRyzskAe37XAo7ETwQt4m0AZbATBgTo4QAR6nr8KMBxAOfFhwFLwaj/Mdlm/S86fv0lT18AvpLhA/wXuv5oAl0AJcxvBFtnBwBCAlkDg/vM/Pf2kwKXSmr2W6w3AlefJvtQ4/0AtU8a+7cntvzPnS0BPBTDBXwEFwZ3Esz8jrYxAhkDAv3T0Ob9jsV3A75y0vwRqXz+VK0ZAi8R8QE+HJEHMazO9/o4jQZMgd0HhDxpBydKfwHY0GsFKhY0/withwJASjL5AFxlBTbd1QLAtqUByAaHAxmw0vwABG8HC4Ay/WebJvnaRFcHSnGtBjXI5wTbmwr/faivByFYFwFQR8MBVtbm/MtUswfNYOcHLTT7A2jw8v1hW3MAsBUHB8wFHv9i2YECcxxvB/A8Twaw/B8GovdzAZn51QBtcBMGwQ8VA0ig5wbksKcGwGrPAfgsUQR4qJ8F6KKtAdGxvQfhBwsARGfxAlynPQIacFEFFtMLAc1/CvwmmuED3TiXBmn4WP+XOkL/7MOe/bW4TQV026r96xrVAI3W0wHFaw8CYNVa/KnIiwbnzssCUzXpBugu3v3rNN0E1p01AFVlKwdF1z0BarFhBruO5wApV7cCArFhBGCy/wBMfxz7vTf2/MeApQc/NBsAJuwbAZRW5vuN0m8BHHZTAOzsdwRtIcL+3gqFAeWIBPk/L+8B1BPnA5K9YQdYRs8BlPFO/uROMQOA/A8GAkyPBRnD+wAvzxkBh1IO/6D2bPkeIBsFs0CrBlmhDPgFJkT/yRsPAqo5vv1w+isAXeZxAq++Cv17UWT9IiAbBHSonwc/aKMCxH0s+AuBJP9UQFMBI/BBBWpdMwWxywsCseLRA/VytQCNmn0BkrbS/CUEUwWvQKsGtRiTBPRAkv4EbIcFOWnpB2K0bv3JYM8HRjDJBjMwWQY7uF0G6VQg/Bld1QTR7Wb/EbnC/1Fc/v9Pog0Ca/pG+meTqQHl528Ck0LpAoSHSQG9e/r9pCt9A+zNxQf6d7kD+xnZByP98QPvjor81CoC/i/86wWCXIUB0fwbBmhqpwK8UX0DkU6i/Vh0vwTG318CD9pu/dKf+v2Rk0kBiIwdByFrcwG4LnECsnyLBJ+KnQPSJtsAGmR1BKGS4QK3jfL65BitB3LQKwdbAn0BnsfPA74NYQdyoKz5e+1C/MeLFv4HBcEHj4d5AM1NLvwn93kBgZRNBwyjtv6x7HcHSCXNA8JQLwbCRxMCqnGtBWQoBwYJ+ksA0HWtB1Tebv+rG6L85CHpBI1EiwSJhC8A/mO1A2KerwMkYrkDp3U9A8d5mQBiPBMFT3xhBzDs5wW1Sa0EgK73Axt8twUeIBsH8qbJA4/sQwTdTuz5euvu9rbtmQC0vN8HvXHRB3/8jwTaY7UBDBB9AseC8wFoppEAs6p9AJ2/tv4QO7b9nLoO/d6BHwbPjRsGAsAvBQqCfQL2cNL+AOd5AJaJIv446WkCcaBPBuMt5v0NT4cAR3oK/5SVBv3hfekFpcUO8/iXawOoSIsHkidvA/pq0wGc9FEEO49HAL6uoQFKDbkEGnrjAUpy0v8bBR79mqzzBL1yjQE87KsEIL/DA+fIwQQ7j0cDiw5/AvDeqvjCiJcGDiHW+7kOqQCzYi0Bj/TC/jGFrQBHREMGO4nC/Tr8dwCltS0DCLRfBmhQFwfougUAzpxhB\",\"dtype\":\"float32\",\"shape\":[330]}}},\"id\":\"a5903060-6dbc-47d6-ac52-81a5c65e9865\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"66262241-fbb4-4009-a948-d18a99ecd47e\",\"type\":\"LinearScale\"},{\"attributes\":{\"below\":[{\"id\":\"0ec49cf4-e8b1-4a93-a554-457c99142110\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"3cda0c1b-b8f5-45be-9f69-49d2e56f91ba\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"0ec49cf4-e8b1-4a93-a554-457c99142110\",\"type\":\"LinearAxis\"},{\"id\":\"b4d7b0fa-1124-435b-8a9b-a2aabd32ede5\",\"type\":\"Grid\"},{\"id\":\"3cda0c1b-b8f5-45be-9f69-49d2e56f91ba\",\"type\":\"LinearAxis\"},{\"id\":\"154ab22f-33ad-4c24-8e9f-b076e9e05fef\",\"type\":\"Grid\"},{\"id\":\"3ac5dce4-c5c9-465b-b47b-4ba571a914c7\",\"type\":\"BoxAnnotation\"},{\"id\":\"1192d09a-0b89-44a8-8458-b0ba5cee3bfa\",\"type\":\"PolyAnnotation\"},{\"id\":\"992c129a-a98b-4dc0-b2f6-f8905d99fec0\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"02fe8423-9fda-46e2-9df7-d5fc4427c433\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"80b3cd37-60d8-4f9d-aec6-d420f541260f\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"000af6c2-0511-4db7-beea-42dbdf72aa9b\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"11012747-75ec-4209-a295-a74dd6e2a252\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"fda8ac98-5244-4081-8647-d4abccc33c22\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"66262241-fbb4-4009-a948-d18a99ecd47e\",\"type\":\"LinearScale\"}},\"id\":\"f29f7668-5ab3-4bfa-b535-dfede8966e2f\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1471aa4f-7171-484d-bce6-2bb092fda359\",\"type\":\"SaveTool\"},{\"attributes\":{\"callback\":null},\"id\":\"fda8ac98-5244-4081-8647-d4abccc33c22\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null,\"overlay\":{\"id\":\"1192d09a-0b89-44a8-8458-b0ba5cee3bfa\",\"type\":\"PolyAnnotation\"}},\"id\":\"6b2a5f90-7a05-4a60-bb31-eafb4632c71e\",\"type\":\"LassoSelectTool\"},{\"attributes\":{\"formatter\":{\"id\":\"9eb5eec4-2b2f-47f3-9a92-d44450ae5d5a\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"f29f7668-5ab3-4bfa-b535-dfede8966e2f\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"861b0bfc-f0a1-43be-a390-8e821b5ca7ef\",\"type\":\"BasicTicker\"}},\"id\":\"0ec49cf4-e8b1-4a93-a554-457c99142110\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"xs_units\":\"screen\",\"ys_units\":\"screen\"},\"id\":\"1192d09a-0b89-44a8-8458-b0ba5cee3bfa\",\"type\":\"PolyAnnotation\"},{\"attributes\":{},\"id\":\"861b0bfc-f0a1-43be-a390-8e821b5ca7ef\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"9eb5eec4-2b2f-47f3-9a92-d44450ae5d5a\",\"type\":\"BasicTickFormatter\"}],\"root_ids\":[\"f29f7668-5ab3-4bfa-b535-dfede8966e2f\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.10\"}};\n",
       "    var render_items = [{\"docid\":\"a26ad894-4951-499e-85d1-323689dd4bcd\",\"elementid\":\"4fb49d02-8f65-4811-ad44-5e550507a78b\",\"modelid\":\"f29f7668-5ab3-4bfa-b535-dfede8966e2f\"}];\n",
       "\n",
       "    root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "  }\n",
       "\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to embed document because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "f29f7668-5ab3-4bfa-b535-dfede8966e2f"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import figure, show, ColumnDataSource\n",
    "\n",
    "x = tsne.embedding_[:, 0]\n",
    "y = tsne.embedding_[:, 1]\n",
    "author_names = [model.id2author[a] for a in authors]\n",
    "\n",
    "# Radius of each point corresponds to the number of documents attributed to that author.\n",
    "scale = 0.1\n",
    "author_sizes = [len(model.author2doc[a]) for a in author_names]\n",
    "radii = [size * scale for size in author_sizes]\n",
    "\n",
    "source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            author_names=author_names,\n",
    "            author_sizes=author_sizes,\n",
    "            radii=radii,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add author names and sizes to mouse-over info.\n",
    "hover = HoverTool(\n",
    "        tooltips=[\n",
    "        (\"author\", \"@author_names\"),\n",
    "        (\"size\", \"@author_sizes\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "p = figure(tools=[hover, 'crosshair,pan,wheel_zoom,box_zoom,reset,save,lasso_select'])\n",
    "p.scatter('x', 'y', radius='radii', source=source, fill_alpha=0.6, line_color=None)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.similarities import MatrixSimilarity\n",
    "\n",
    "# Generate a similarity object for the transformed corpus.\n",
    "index = MatrixSimilarity(model[list(model.id2author.values())])\n",
    "\n",
    "# Get similarities to some author.\n",
    "author_name = 'Stelzeneder D'\n",
    "sims = index[model[author_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a function that returns similarities based on the Hellinger distance.\n",
    "\n",
    "from gensim import matutils\n",
    "import pandas as pd\n",
    "\n",
    "# Make a list of all the author-topic distributions.\n",
    "author_vecs = [model.get_author_topics(author) for author in model.id2author.values()]\n",
    "\n",
    "def similarity(vec1, vec2):\n",
    "    '''Get similarity between two vectors'''\n",
    "    dist = matutils.hellinger(matutils.sparse2full(vec1, model.num_topics), \\\n",
    "                              matutils.sparse2full(vec2, model.num_topics))\n",
    "    sim = 1.0 / (1.0 + dist)\n",
    "    return sim\n",
    "\n",
    "def get_sims(vec):\n",
    "    '''Get similarity of vector to all authors.'''\n",
    "    sims = [similarity(vec, vec2) for vec2 in author_vecs]\n",
    "    return sims\n",
    "\n",
    "def get_table(name, top_n=10, smallest_author=1):\n",
    "    '''\n",
    "    Get table with similarities, author names, and author sizes.\n",
    "    Return `top_n` authors as a dataframe.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Get similarities.\n",
    "    sims = get_sims(model.get_author_topics(name))\n",
    "\n",
    "    # Arrange author names, similarities, and author sizes in a list of tuples.\n",
    "    table = []\n",
    "    for elem in enumerate(sims):\n",
    "        author_name = model.id2author[elem[0]]\n",
    "        sim = elem[1]\n",
    "        author_size = len(model.author2doc[author_name])\n",
    "        if author_size >= smallest_author:\n",
    "            table.append((author_name, sim, author_size))\n",
    "            \n",
    "    # Make dataframe and retrieve top authors.\n",
    "    df = pd.DataFrame(table, columns=['Author', 'Score', 'Size'])\n",
    "    df = df.sort_values('Score', ascending=False)[:top_n]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Score</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Stelzeneder D</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Scheurecker G</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Welsch GH</td>\n",
       "      <td>0.966961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Vlychou M</td>\n",
       "      <td>0.941210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Friedrich KM</td>\n",
       "      <td>0.757013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Mulder CJ</td>\n",
       "      <td>0.740610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akyazi H</td>\n",
       "      <td>0.737258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Kara IH</td>\n",
       "      <td>0.712800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Mungan S</td>\n",
       "      <td>0.691935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Punta G</td>\n",
       "      <td>0.679087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author     Score  Size\n",
       "276  Stelzeneder D  1.000000     1\n",
       "263  Scheurecker G  0.997696     1\n",
       "305      Welsch GH  0.966961     1\n",
       "300      Vlychou M  0.941210     1\n",
       "92    Friedrich KM  0.757013     1\n",
       "207      Mulder CJ  0.740610     1\n",
       "4         Akyazi H  0.737258     1\n",
       "148        Kara IH  0.712800     1\n",
       "209       Mungan S  0.691935     1\n",
       "243        Punta G  0.679087     1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_table('Stelzeneder D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
